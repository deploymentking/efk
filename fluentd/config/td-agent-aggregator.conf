####
## Source descriptions:
##

#secure input source from log shippers
<source>
	@type secure_forward
	shared_key "#{ENV['FLUENTD_SHARED_KEY']}"
	self_hostname "#{ENV['FLUENTD_HOSTNAME']}"
	#cert_auto_generate yes

	ca_cert_path /fluentd/certs/ca_cert.pem
	ca_private_key_path /fluentd/certs/ca_key.pem
	ca_private_key_passphrase "#{ENV['FLUENTD_PRIVATE_KEY_PASSPHRASE']}"

	secure true

	#for authentication
	authentication no
	<user>
		username "#{ENV['FLUENTD_SECURE_USERNAME']}"
		password "#{ENV['FLUENTD_SECURE_PASSWORD']}"
	</user>

# Enabling this will allow only known hosts & user combinations
#	allow_anonymous_source no
#	<client>
#		network 172.18.20.97
#		users akai4life
		#also can use 'host akai.hl-network.adns.de'
#	</client>
</source>

####
## Output descriptions:
##

<match internal.**>
## We will send to both elasticsearch and stdout
    @type copy
    <store>
        @type elasticsearch
        logstash_format true
        include_timestamp true
        host elasticsearch
				port 9200
    </store>
    <store>
    #All events pushed to stdout while fluentd is running as a service will be
    #appended to the td-agent log if started as service or to the console output
		#if started with docker-compose
        @type stdout
    </store>
</match>

#This is where log messages go to die :)
<match clear>
    @type null
</match>

#Log events captured by the rewrite_tag filter or output plugin will cause
#the events to be re-emitted so that they can be re-matched with their new
#tag by previously enumerated filters and match nodes.
#<match **>
#    @type rewrite_tag_filter
#    <rule>
#        key     message
#        pattern .*
#        tag     clear
#    </rule>
#    <rule>
#        key     sourceProject
#        pattern ^yourProjectName$
#        tag     internal.yourProjectName
#    </rule>
#</match>
